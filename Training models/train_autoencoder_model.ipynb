{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_autoencoder_model",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5aHoS5BOHknk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "bc6a6631-03ad-4ae1-bf55-b75ad26d98d2"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=2232d9a44c2c95555507d10b4b3d65e9d29316f5431573e4b3ee148c3eb4d298\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 159.0 MB\n",
            "GPU RAM Free: 7611MB | Used: 0MB | Util   0% | Total 7611MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vB0_O_2_HpJj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ee3c7b55-d176-4c3e-c68b-20c1a3caf75a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive') \n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLjMvjrpJPu3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "77d23efc-d726-49cc-faa2-a0300db2e910"
      },
      "source": [
        "pip install mido"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mido\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/0a/81beb587b1ae832ea6a1901dc7c6faa380e8dd154e0a862f0a9f3d2afab9/mido-1.2.9-py2.py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 35.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 28.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-cJrZwKnH-4E",
        "colab": {}
      },
      "source": [
        "from mido import MidiFile, MidiTrack, Message\n",
        "import numpy as np\n",
        "\n",
        "num_notes = 118\n",
        "samples_per_measure = 118\n",
        "\n",
        "def midi_to_samples(fname):\n",
        "    print(fname)\n",
        "    has_time_sig = False\n",
        "    flag_warning = False\n",
        "    mid = MidiFile(fname)\n",
        "    ticks_per_beat = mid.ticks_per_beat\n",
        "    ticks_per_measure = 4 * ticks_per_beat\n",
        "\n",
        "    for i, track in enumerate(mid.tracks):\n",
        "        for msg in track:\n",
        "            if msg.type == 'time_signature':\n",
        "                new_tpm = msg.numerator * ticks_per_beat * 4 / msg.denominator\n",
        "                if has_time_sig and new_tpm != ticks_per_measure:\n",
        "                    flag_warning = True\n",
        "                ticks_per_measure = new_tpm\n",
        "                has_time_sig = True\n",
        "    if flag_warning:\n",
        "        print(\"  ^^^^^^ WARNING ^^^^^^\")\n",
        "        print(\"    \" + fname)\n",
        "        print(\"    Detected multiple distinct time signatures.\")\n",
        "        print(\"  ^^^^^^ WARNING ^^^^^^\")\n",
        "        return []\n",
        "\n",
        "    all_notes = {}\n",
        "    for i, track in enumerate(mid.tracks):\n",
        "        abs_time = 0\n",
        "        for msg in track:\n",
        "            abs_time += msg.time\n",
        "            if msg.type == 'note_on':\n",
        "                if msg.velocity == 0:\n",
        "                    continue\n",
        "            # print(\"Msg : \",msg)\n",
        "                note = msg.note - (128 - num_notes)/2\n",
        "            # print(note)\n",
        "                assert(note >= 0 and note < num_notes)\n",
        "                if note not in all_notes:\n",
        "                    all_notes[note] = []\n",
        "                else:\n",
        "                    single_note = all_notes[note][-1]\n",
        "                    if len(single_note) == 1:\n",
        "                        single_note.append(single_note[0] + 1)\n",
        "                all_notes[note].append([abs_time * samples_per_measure / ticks_per_measure])\n",
        "            elif msg.type == 'note_off':\n",
        "                note = msg.note - (128 - num_notes)/2\n",
        "                if note not in all_notes:\n",
        "                    continue\n",
        "                if len(all_notes[note][-1]) != 1:\n",
        "                    continue\n",
        "                all_notes[note][-1].append(abs_time * samples_per_measure / ticks_per_measure)\n",
        "    for note in all_notes:\n",
        "        for start_end in all_notes[note]:\n",
        "            if len(start_end) == 1:\n",
        "                start_end.append(start_end[0] + 1)\n",
        "    samples = []\n",
        "    for note in all_notes:\n",
        "        for start, end in all_notes[note]:\n",
        "            note=int(note)\n",
        "      # print(note)\n",
        "            sample_ix = int(start / samples_per_measure)\n",
        "            while len(samples) <= sample_ix:\n",
        "                samples.append(np.zeros((samples_per_measure, num_notes), dtype=np.uint8))\n",
        "      # print(samples)\n",
        "#             sample = samples[sample_ix]\n",
        "      # print(sample_ix)\n",
        "            start_ix = start - sample_ix * samples_per_measure\n",
        "      # print(start_ix)\n",
        "            if False:\n",
        "                end_ix = min(end - sample_ix * samples_per_measure, samples_per_measure)\n",
        "                while start_ix < end_ix:\n",
        "                    samples[sample_ix][int(start_ix)][note] = 1\n",
        "                    start_ix += 1\n",
        "            else:\n",
        "                samples[sample_ix][int(start_ix)][note] = 1\n",
        "    return samples\n",
        "\n",
        "def samples_to_midi(samples, fname, ticks_per_sample, thresh=0.5):\n",
        "\tmid = MidiFile()\n",
        "\ttrack = MidiTrack()\n",
        "\tmid.tracks.append(track)\n",
        "\tticks_per_beat = mid.ticks_per_beat\n",
        "\tticks_per_measure = 4 * ticks_per_beat\n",
        "\tticks_per_sample = int(ticks_per_measure / samples_per_measure)\n",
        "\tabs_time = 0\n",
        "\tlast_time = 0\n",
        "\tfor sample in samples:\n",
        "\t\tfor y in range(sample.shape[0]):\n",
        "\t\t\tabs_time += ticks_per_sample\n",
        "\t\t\tfor x in range(sample.shape[1]):\n",
        "\t\t\t\tnote = int(x + (128 - num_notes)/2)\n",
        "\t\t\t\tif sample[y,x] >= thresh and (y == 0 or sample[y-1,x] < thresh):\n",
        "\t\t\t\t\tdelta_time = abs_time - last_time\n",
        "\t\t\t\t\ttrack.append(Message('note_on', note=note, velocity=127, time=delta_time))\n",
        "\t\t\t\t\tlast_time = abs_time\n",
        "\t\t\t\tif sample[y,x] >= thresh and (y == sample.shape[0]-1 or sample[y+1,x] < thresh):\n",
        "\t\t\t\t\tdelta_time = abs_time - last_time\n",
        "\t\t\t\t\ttrack.append(Message('note_off', note=note, velocity=127, time=delta_time))\n",
        "\t\t\t\t\tlast_time = abs_time\n",
        "\tmid.save(fname)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQgWkS3_0ZIC",
        "colab": {}
      },
      "source": [
        "def transpose_range(samples):\n",
        "\tmerged_sample = np.zeros_like(samples[0])\n",
        "\tfor sample in samples:\n",
        "\t\tmerged_sample = np.maximum(merged_sample, sample)\n",
        "\tmerged_sample = np.amax(merged_sample, axis=0)\n",
        "\tmin_note = np.argmax(merged_sample)\n",
        "\tmax_note = merged_sample.shape[0] - np.argmax(merged_sample[::-1])\n",
        "\treturn min_note, max_note"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "igJPXIYwIRPx",
        "colab": {}
      },
      "source": [
        "def generate_add_centered_transpose(samples):\n",
        "\tnum_notes = samples[0].shape[1]\n",
        "\tmin_note, max_note = transpose_range(samples)\n",
        "\ts = int(num_notes/2 - (max_note + min_note)/2)\n",
        "\tout_samples = samples\n",
        "\tout_lens = [len(samples), len(samples)]\n",
        "\tfor i in range(len(samples)):\n",
        "\t\tout_sample = np.zeros_like(samples[i])\n",
        "\t\tout_sample[:,min_note+s:max_note+s] = samples[i][:,min_note:max_note]\n",
        "\t\tout_samples.append(out_sample)\n",
        "\treturn out_samples, out_lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ANALFQXMxaj-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dabbc40-6470-4ed1-8f85-df011d88387d"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "patterns = {}\n",
        "dirs = [\"/gdrive/My Drive/midi_songs/\", \"download\", \"rag\", \"pop\", \"misc\"]\n",
        "all_samples = []\n",
        "all_lens = []\n",
        "print(\"Loading Songs...\")\n",
        "for dir in dirs:\n",
        "    for root, subdirs, files in os.walk(dir):\n",
        "        for file in files:\n",
        "            path = root + '/' + file\n",
        "            if not (path.endswith('.mid') or path.endswith('.midi')):\n",
        "                continue\n",
        "            # try:\n",
        "            samples = midi_to_samples(path)\n",
        "            # \t\t\tprint(samples)\n",
        "            # except:\n",
        "            # \tprint(\"ERROR \", path)\n",
        "                # continue\n",
        "            if len(samples) < 8:\n",
        "                continue\n",
        "\n",
        "            samples, lens = generate_add_centered_transpose(samples)\n",
        "            all_samples += samples\n",
        "            all_lens += lens\n",
        "\n",
        "# print(all_samples)\n",
        "assert(sum(all_lens) == len(all_samples))\n",
        "print(\"Saving \" + str(len(all_samples)) + \" samples...\")\n",
        "all_samples = np.array(all_samples, dtype=np.uint8)\n",
        "all_lens = np.array(all_lens, dtype=np.uint32)\n",
        "np.save('/gdrive/My Drive/BeProject_v3/samples.npy', all_samples)\n",
        "np.save('/gdrive/My Drive/BeProject_v3/lengths.npy', all_lens)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Songs...\n",
            "/gdrive/My Drive/midi_songs//0fithos.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//0fithos.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//AT.mid\n",
            "/gdrive/My Drive/midi_songs//ahead_on_our_way_piano.mid\n",
            "/gdrive/My Drive/midi_songs//balamb.mid\n",
            "/gdrive/My Drive/midi_songs//8.mid\n",
            "/gdrive/My Drive/midi_songs//BlueStone_LastDungeon.mid\n",
            "/gdrive/My Drive/midi_songs//bcm.mid\n",
            "/gdrive/My Drive/midi_songs//caitsith.mid\n",
            "/gdrive/My Drive/midi_songs//Cids.mid\n",
            "/gdrive/My Drive/midi_songs//braska.mid\n",
            "/gdrive/My Drive/midi_songs//cosmo.mid\n",
            "/gdrive/My Drive/midi_songs//costadsol.mid\n",
            "/gdrive/My Drive/midi_songs//dontbeafraid.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//dontbeafraid.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//dayafter.mid\n",
            "/gdrive/My Drive/midi_songs//DOS.mid\n",
            "/gdrive/My Drive/midi_songs//decisive.mid\n",
            "/gdrive/My Drive/midi_songs//ff11_awakening_piano.mid\n",
            "/gdrive/My Drive/midi_songs//EyesOnMePiano.mid\n",
            "/gdrive/My Drive/midi_songs//Eternal_Harvest.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//Eternal_Harvest.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//electric_de_chocobo.mid\n",
            "/gdrive/My Drive/midi_songs//ff1battp.mid\n",
            "/gdrive/My Drive/midi_songs//ff4-airship.mid\n",
            "/gdrive/My Drive/midi_songs//Ff4-BattleLust.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//Ff4-BattleLust.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//ff4-fight1.mid\n",
            "/gdrive/My Drive/midi_songs//FF3_Third_Phase_Final_(Piano).mid\n",
            "/gdrive/My Drive/midi_songs//FF3_Battle_(Piano).mid\n",
            "/gdrive/My Drive/midi_songs//ff4-town.mid\n",
            "/gdrive/My Drive/midi_songs//ff4_piano_collections-main_theme.mid\n",
            "/gdrive/My Drive/midi_songs//ff4pclov.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//ff4pclov.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//FF4.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//FF4.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//FF6epitaph_piano.mid\n",
            "/gdrive/My Drive/midi_songs//ff7-mainmidi.mid\n",
            "/gdrive/My Drive/midi_songs//ff7themep.mid\n",
            "/gdrive/My Drive/midi_songs//ff6shap.mid\n",
            "/gdrive/My Drive/midi_songs//Ff7-Cinco.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//Ff7-Cinco.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//Ff7-Jenova_Absolute.mid\n",
            "/gdrive/My Drive/midi_songs//Ff7-One_Winged.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//Ff7-One_Winged.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//ff8-lfp.mid\n",
            "/gdrive/My Drive/midi_songs//FFIII_Edgar_And_Sabin_Piano.mid\n",
            "/gdrive/My Drive/midi_songs//FF8_Shuffle_or_boogie_pc.mid\n",
            "/gdrive/My Drive/midi_songs//FFIX_Piano.mid\n",
            "/gdrive/My Drive/midi_songs//Fiend_Battle_(Piano).mid\n",
            "/gdrive/My Drive/midi_songs//FFIXQuMarshP.mid\n",
            "/gdrive/My Drive/midi_songs//Fierce_Battle_(Piano).mid\n",
            "/gdrive/My Drive/midi_songs//FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//FFVII_BATTLE.mid\n",
            "/gdrive/My Drive/midi_songs//Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "/gdrive/My Drive/midi_songs//Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "/gdrive/My Drive/midi_songs//Finalfantasy5gilgameshp.mid\n",
            "/gdrive/My Drive/midi_songs//figaro.mid\n",
            "/gdrive/My Drive/midi_songs//Finalfantasy6fanfarecomplete.mid\n",
            "/gdrive/My Drive/midi_songs//fortresscondor.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//fortresscondor.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//HighwindTakestotheSkies.mid\n",
            "/gdrive/My Drive/midi_songs//Gold_Silver_Rival_Battle.mid\n",
            "/gdrive/My Drive/midi_songs//goldsaucer.mid\n",
            "/gdrive/My Drive/midi_songs//gerudo.mid\n",
            "/gdrive/My Drive/midi_songs//great_war.mid\n",
            "/gdrive/My Drive/midi_songs//Fyw_piano.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//Fyw_piano.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//In_Zanarkand.mid\n",
            "/gdrive/My Drive/midi_songs//JENOVA.mid\n",
            "/gdrive/My Drive/midi_songs//Kingdom_Hearts_Dearly_Beloved.mid\n",
            "/gdrive/My Drive/midi_songs//Kingdom_Hearts_Traverse_Town.mid\n",
            "/gdrive/My Drive/midi_songs//OTD5YA.mid\n",
            "/gdrive/My Drive/midi_songs//pkelite4.mid\n",
            "/gdrive/My Drive/midi_songs//lurk_in_dark.mid\n",
            "/gdrive/My Drive/midi_songs//Life_Stream.mid\n",
            "/gdrive/My Drive/midi_songs//Oppressed.mid\n",
            "/gdrive/My Drive/midi_songs//mining.mid\n",
            "/gdrive/My Drive/midi_songs//Rachel_Piano_tempofix.mid\n",
            "/gdrive/My Drive/midi_songs//path_of_repentance.mid\n",
            "/gdrive/My Drive/midi_songs//redwings.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//redwings.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//roseofmay-piano.mid\n",
            "/gdrive/My Drive/midi_songs//Rydia_pc.mid\n",
            "/gdrive/My Drive/midi_songs//rufus.mid\n",
            "/gdrive/My Drive/midi_songs//relmstheme-piano.mid\n",
            "/gdrive/My Drive/midi_songs//Still_Alive-1.mid\n",
            "/gdrive/My Drive/midi_songs//sobf.mid\n",
            "/gdrive/My Drive/midi_songs//sera_.mid\n",
            "/gdrive/My Drive/midi_songs//sandy.mid\n",
            "/gdrive/My Drive/midi_songs//Suteki_Da_Ne_(Piano_Version).mid\n",
            "/gdrive/My Drive/midi_songs//thenightmarebegins.mid\n",
            "/gdrive/My Drive/midi_songs//tpirtsd-piano.mid\n",
            "/gdrive/My Drive/midi_songs//tifap.mid\n",
            "/gdrive/My Drive/midi_songs//traitor.mid\n",
            "/gdrive/My Drive/midi_songs//thoughts.mid\n",
            "/gdrive/My Drive/midi_songs//ultimafro.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//ultimafro.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//ultros.mid\n",
            "/gdrive/My Drive/midi_songs//VincentPiano.mid\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "    /gdrive/My Drive/midi_songs//VincentPiano.mid\n",
            "    Detected multiple distinct time signatures.\n",
            "  ^^^^^^ WARNING ^^^^^^\n",
            "/gdrive/My Drive/midi_songs//waltz_de_choco.mid\n",
            "/gdrive/My Drive/midi_songs//ViviinAlexandria.mid\n",
            "/gdrive/My Drive/midi_songs//z_aeristhemepiano.mid\n",
            "/gdrive/My Drive/midi_songs//Zelda_Overworld.mid\n",
            "Saving 9298 samples...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d25fh95PNHyT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "298af5a3-9f25-491f-e815-6afe835e013d"
      },
      "source": [
        "print((all_lens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 75  75  84  84  70  70  21  21  78  78  60  60 104 104  64  64  34  34\n",
            " 102 102  32  32  56  56  66  66  46  46  83  83  70  70  62  62  52  52\n",
            "  30  30  68  68  89  89  39  39  48  48  92  92  24  24  24  24  57  57\n",
            "  72  72  62  62 111 111  54  54  69  69  32  32  75  75  52  52  48  48\n",
            "  27  27  35  35  41  41  68  68  34  34  50  50  81  81  94  94  88  88\n",
            "  78  78  82  82  79  79 100 100  32  32  32  32  54  54  21  21  31  31\n",
            "  94  94  40  40  28  28  59  59  35  35  74  74  66  66  60  60  43  43\n",
            "  59  59  70  70  47  47  68  68  95  95  80  80  64  64  49  49  45  45\n",
            "  34  34  64  64  30  30 122 122  43  43  48  48]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NhICeQarNj_y",
        "colab": {}
      },
      "source": [
        "# from mido import MidiFile, MidiTrack, Message, tick2second\n",
        "# mid = MidiFile('/Users/drdevashishojaiswal/Documents/be_project/midi_songs/FFVII_BATTLE.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xol7604jPzrA",
        "colab": {}
      },
      "source": [
        "# print(mid.length)\n",
        "# num_notes = 118\n",
        "# samples_per_measure = 118\n",
        "# has_time_sig=False\n",
        "# flag_warning =False\n",
        "# ticks_per_beat = mid.ticks_per_beat\n",
        "# ticks_per_measure = 4 * ticks_per_beat\n",
        "# for i, track in enumerate(mid.tracks):\n",
        "#     for msg in track:\n",
        "#         if msg.type == 'time_signature':\n",
        "# #             print(msg)\n",
        "#             new_tpm = msg.numerator * ticks_per_beat * 4 / msg.denominator\n",
        "#             if has_time_sig and new_tpm != ticks_per_measure:\n",
        "#                 flag_warning = True\n",
        "#             ticks_per_measure = new_tpm\n",
        "#             has_time_sig = True\n",
        "# if flag_warning:\n",
        "#     print(\"  ^^^^^^ WARNING ^^^^^^\")\n",
        "#     print(\"    \" + fname)\n",
        "#     print(\"    Detected multiple distinct time signatures.\")\n",
        "#     print(\"  ^^^^^^ WARNING ^^^^^^\")\n",
        "#     print(\"STOOOOOP\")\n",
        "# all_notes=dict()\n",
        "# for i, track in enumerate(mid.tracks):\n",
        "#     print(track)\n",
        "#     abs_time=0\n",
        "#     for msg in track:\n",
        "# #         print(msg)\n",
        "#         abs_time += msg.time\n",
        "#         if msg.type == 'note_on':\n",
        "#             if(msg.velocity == 0):\n",
        "#                 continue\n",
        "# #             print(msg.note,abs_time)\n",
        "#             note = msg.note - (128 - num_notes)/2\n",
        "# #             print(msg)\n",
        "# #             if(msg.note<17):\n",
        "# #                 print(\"Sdsdvvvvvsvadnacdhagcenacsdngcehcqhed\")\n",
        "#             assert(note >= 0 and note < num_notes)\n",
        "#             if note not in all_notes:\n",
        "#                 all_notes[note] = []\n",
        "#             else:\n",
        "#                 single_note = all_notes[note][-1]\n",
        "#                 if len(single_note) == 1:\n",
        "#                     single_note.append(single_note[0] + 1)\n",
        "#             all_notes[note].append([abs_time * samples_per_measure / ticks_per_measure])\n",
        "#         elif msg.type == 'note_off':\n",
        "#             note = msg.note - (128 - num_notes)/2\n",
        "#             if note not in all_notes:\n",
        "#                 continue\n",
        "#             if len(all_notes[note][-1]) != 1:\n",
        "#                 continue\n",
        "#             all_notes[note][-1].append(abs_time * samples_per_measure / ticks_per_measure)\n",
        "# #         print(tick2second(abs_time,ticks_per_beat, 666666))\n",
        "# # print(all_notes)\n",
        "# for note in all_notes:\n",
        "#         for start_end in all_notes[note]:\n",
        "#             if len(start_end) == 1:\n",
        "#                 start_end.append(start_end[0] + 1)\n",
        "# # print(all_notes)\n",
        "# samples = []\n",
        "# for note in all_notes:\n",
        "# #     print(note)\n",
        "#     for start, end in all_notes[note]:\n",
        "# #         print(start,end)\n",
        "#         note=int(note)\n",
        "#   # print(note)\n",
        "#         sample_ix = int(start / samples_per_measure)\n",
        "# #         print(sample_ix)\n",
        "#         while len(samples) <= sample_ix:\n",
        "#             samples.append(np.zeros((samples_per_measure, num_notes), dtype=np.uint8))\n",
        "#   # print(samples)\n",
        "# #         sample = samples[sample_ix]\n",
        "#   # print(sample_ix)\n",
        "#         start_ix = start - sample_ix * samples_per_measure\n",
        "# #         print(sample_ix,start_ix)\n",
        "#         if False:\n",
        "#             end_ix = min(end - sample_ix * samples_per_measure, samples_per_measure)\n",
        "#             while start_ix < end_ix:\n",
        "#                 samples[sample_ix][int(start_ix)][note] = 1\n",
        "#                 start_ix += 1\n",
        "#         else:\n",
        "#             samples[sample_ix][int(start_ix)][note] = 1\n",
        "            \n",
        "# print((samples[0][0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipUEKNH3P3Uv",
        "colab": {}
      },
      "source": [
        "# print(tick2second(abs_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AaHfZAyb0Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if False:\n",
        "#     print(dssdfsd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh5snXmkb0A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Loading Data...\")\n",
        "# y_samples = np.load('/gdrive/My Drive/samples.npy')\n",
        "# y_lengths = np.load('/gdrive/My Drive/lengths.npy')\n",
        "# num_samples = y_samples.shape[0]\n",
        "# num_songs = y_lengths.shape[0]\n",
        "# print(\"Loaded \" + str(num_samples) + \" samples from \" + str(num_songs) + \" songs.\")\n",
        "# print(np.sum(y_lengths))\n",
        "# assert(np.sum(y_lengths) == num_samples)\n",
        "\n",
        "# print(\"Padding Songs...\")\n",
        "# x_shape = (num_songs * 1, 1)\n",
        "# y_shape = (num_songs * 1, 16) + y_samples.shape[1:]\n",
        "# x_orig = np.expand_dims(np.arange(x_shape[0]), axis=-1)\n",
        "# y_orig = np.zeros(y_shape, dtype=y_samples.dtype)\n",
        "# cur_ix = 0\n",
        "# for i in range(num_songs):\n",
        "# \tfor ofs in range(1):\n",
        "# \t\tix = i*1 + ofs\n",
        "# \t\tend_ix = cur_ix + y_lengths[i]\n",
        "# \t\tfor j in range(1):\n",
        "# \t\t\tk = (j + ofs) % (end_ix - cur_ix)\n",
        "# \t\t\ty_orig[ix,j] = y_samples[cur_ix + k]\n",
        "# \tcur_ix = end_ix\n",
        "# assert(end_ix == num_samples)\n",
        "# x_train = np.copy(x_orig)\n",
        "# y_train = np.copy(y_orig)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHwjDhWFb0A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_ix = 0\n",
        "# y_test_song = np.copy(y_train[test_ix:test_ix+1])\n",
        "# x_test_song = np.copy(x_train[test_ix:test_ix+1])\n",
        "# samples_to_midi(y_test_song[0], '/Users/drdevashishojaiswal/Documents/be_project/gt.mid', 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1j5uptb0A6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a89bf8b9-2229-4db2-a4a6-e65e3c82432f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-785c9f7381fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_song\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test_song' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRp6nk-3b0BA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8ynn6PWcQDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, random, os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "NUM_EPOCHS = 2000\n",
        "LR = 0.001\n",
        "CONTINUE_TRAIN = False\n",
        "PLAY_ONLY = False\n",
        "USE_EMBEDDING = False\n",
        "USE_VAE = False\n",
        "WRITE_HISTORY = True\n",
        "NUM_RAND_SONGS = 10\n",
        "DO_RATE = 0.1\n",
        "BN_M = 0.9\n",
        "VAE_B1 = 0.02\n",
        "VAE_B2 = 0.1\n",
        "\n",
        "BATCH_SIZE = 350\n",
        "MAX_LENGTH = 16\n",
        "PARAM_SIZE = 120\n",
        "NUM_OFFSETS = 16 if USE_EMBEDDING else 1\n",
        "\n",
        "def plotScores(scores, fname, on_top=True):\n",
        "\tplt.clf()\n",
        "\tax = plt.gca()\n",
        "\tax.yaxis.tick_right()\n",
        "\tax.yaxis.set_ticks_position('both')\n",
        "\tax.yaxis.grid(True)\n",
        "\tplt.plot(scores)\n",
        "\tplt.ylim([0.0, 0.009])\n",
        "\tplt.xlabel('Epoch')\n",
        "\tloc = ('upper right' if on_top else 'lower right')\n",
        "\tplt.draw()\n",
        "\tplt.savefig(fname)\n",
        "\n",
        "def save_config():\n",
        "\twith open('/gdrive/My Drive/BeProject_v3/config.txt', 'w') as fout:\n",
        "\t\tfout.write('LR:          ' + str(LR) + '\\n')\n",
        "\t\tfout.write('BN_M:        ' + str(BN_M) + '\\n')\n",
        "\t\tfout.write('BATCH_SIZE:  ' + str(BATCH_SIZE) + '\\n')\n",
        "\t\tfout.write('NUM_OFFSETS: ' + str(NUM_OFFSETS) + '\\n')\n",
        "\t\tfout.write('DO_RATE:     ' + str(DO_RATE) + '\\n')\n",
        "\t\tfout.write('num_songs:   ' + str(num_songs) + '\\n')\n",
        "\t\tfout.write('optimizer:   ' + type(model.optimizer).__name__ + '\\n')\n",
        "\n",
        "###################################\n",
        "#  Load Keras\n",
        "###################################\n",
        "print(\"Loading Keras...\")\n",
        "import os, math\n",
        "# os.environ['THEANORC'] = \"./gpu.theanorc\"\n",
        "# os.environ['KERAS_BACKEND'] = \"theano\"\n",
        "# import theano\n",
        "# print(\"Theano Version: \" + theano.__version__)\n",
        "\n",
        "import keras\n",
        "print(\"Keras Version: \" + keras.__version__)\n",
        "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Reshape, Permute, RepeatVector, ActivityRegularization, TimeDistributed, Lambda, SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, Conv2D, Conv2DTranspose, UpSampling2D, ZeroPadding2D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.local import LocallyConnected2D\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.engine.topology import Layer\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "#Fix the random seed so that training comparisons are easier to make\n",
        "# np.random.seed(0)\n",
        "# random.seed(0)\n",
        "\n",
        "if WRITE_HISTORY:\n",
        "\t#Create folder to save models into\n",
        "\tif not os.path.exists('/gdrive/My Drive/BeProject_v3/History'):\n",
        "\t\tos.makedirs('/gdrive/My Drive/BeProject_v3/History')\n",
        "\n",
        "###################################\n",
        "#  Load Dataset\n",
        "###################################\n",
        "print(\"Loading Data...\")\n",
        "y_samples = np.load('/gdrive/My Drive/samples.npy')\n",
        "y_lengths = np.load('/gdrive/My Drive/lengths.npy')\n",
        "num_samples = y_samples.shape[0]\n",
        "num_songs = y_lengths.shape[0]\n",
        "print(\"Loaded \" + str(num_samples) + \" samples from \" + str(num_songs) + \" songs.\")\n",
        "print(np.sum(y_lengths))\n",
        "assert(np.sum(y_lengths) == num_samples)\n",
        "\n",
        "print(\"Padding Songs...\")\n",
        "x_shape = (num_songs * NUM_OFFSETS, 1)\n",
        "y_shape = (num_songs * NUM_OFFSETS, MAX_LENGTH) + y_samples.shape[1:]\n",
        "x_orig = np.expand_dims(np.arange(x_shape[0]), axis=-1)\n",
        "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)\n",
        "cur_ix = 0\n",
        "for i in range(num_songs):\n",
        "\tfor ofs in range(NUM_OFFSETS):\n",
        "\t\tix = i*NUM_OFFSETS + ofs\n",
        "\t\tend_ix = cur_ix + y_lengths[i]\n",
        "\t\tfor j in range(MAX_LENGTH):\n",
        "\t\t\tk = (j + ofs) % (end_ix - cur_ix)\n",
        "\t\t\ty_orig[ix,j] = y_samples[cur_ix + k]\n",
        "\tcur_ix = end_ix\n",
        "assert(end_ix == num_samples)\n",
        "x_train = np.copy(x_orig)\n",
        "y_train = np.copy(y_orig)\n",
        "\n",
        "def to_song(encoded_output):\n",
        "\treturn np.squeeze(decoder([np.round(encoded_output), 0])[0])\n",
        "\n",
        "def reg_mean_std(x):\n",
        "\ts = K.log(K.sum(x * x))\n",
        "\treturn s*s\n",
        "\n",
        "def vae_sampling(args):\n",
        "\tz_mean, z_log_sigma_sq = args\n",
        "\tepsilon = K.random_normal(shape=K.shape(z_mean), mean=0.0, stddev=VAE_B1)\n",
        "\treturn z_mean + K.exp(z_log_sigma_sq * 0.5) * epsilon\n",
        "\n",
        "def vae_loss(x, x_decoded_mean):\n",
        "\txent_loss = binary_crossentropy(x, x_decoded_mean)\n",
        "\tkl_loss = VAE_B2 * K.mean(1 + z_log_sigma_sq - K.square(z_mean) - K.exp(z_log_sigma_sq), axis=None)\n",
        "\treturn xent_loss - kl_loss\n",
        "\t\n",
        "test_ix = 0\n",
        "y_test_song = np.copy(y_train[test_ix:test_ix+1])\n",
        "x_test_song = np.copy(x_train[test_ix:test_ix+1])\n",
        "samples_to_midi(y_test_song[0], '/gdrive/My Drive/BeProject_v3/gt.mid', 16)\n",
        "\n",
        "###################################\n",
        "#  Create Model\n",
        "###################################\n",
        "if CONTINUE_TRAIN or PLAY_ONLY:\n",
        "\tprint(\"Loading Model...\")\n",
        "\tmodel = load_model('model.h5', custom_objects=custom_objects)\n",
        "else:\n",
        "\tprint(\"Building Model...\")\n",
        "\n",
        "\tif USE_EMBEDDING:\n",
        "\t\tx_in = Input(shape=x_shape[1:])\n",
        "\t\tprint((None,) + x_shape[1:])\n",
        "\t\tx = Embedding(x_train.shape[0], PARAM_SIZE, input_length=1)(x_in)\n",
        "\t\tx = Flatten(name='pre_encoder')(x)\n",
        "\telse:\n",
        "\t\tx_in = Input(shape=y_shape[1:])\n",
        "\t\tprint((None,) + y_shape[1:])\n",
        "\t\tx = Reshape((y_shape[1], -1))(x_in)\n",
        "\t\tprint(K.int_shape(x))\n",
        "\t\t\n",
        "\t\tx = TimeDistributed(Dense(2000, activation='relu'))(x)\n",
        "\t\tprint(K.int_shape(x))\n",
        "\t\t\n",
        "\t\tx = TimeDistributed(Dense(200, activation='relu'))(x)\n",
        "\t\tprint(K.int_shape(x))\n",
        "\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tprint(K.int_shape(x))\n",
        "\n",
        "\t\tx = Dense(1600, activation='relu')(x)\n",
        "\t\tprint(K.int_shape(x))\n",
        "\t\t\n",
        "\t\tif USE_VAE:\n",
        "\t\t\tz_mean = Dense(PARAM_SIZE)(x)\n",
        "\t\t\tz_log_sigma_sq = Dense(PARAM_SIZE)(x)\n",
        "\t\t\tx = Lambda(vae_sampling, output_shape=(PARAM_SIZE,), name='pre_encoder')([z_mean, z_log_sigma_sq])\n",
        "\t\telse:\n",
        "\t\t\tx = Dense(PARAM_SIZE)(x)\n",
        "\t\t\tx = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\t\n",
        "\tx = Dense(1600, name='encoder')(x)\n",
        "\tx = BatchNormalization(momentum=BN_M)(x)\n",
        "\tx = Activation('relu')(x)\n",
        "\tif DO_RATE > 0:\n",
        "\t\tx = Dropout(DO_RATE)(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\n",
        "\tx = Dense(MAX_LENGTH * 200)(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\tx = Reshape((MAX_LENGTH, 200))(x)\n",
        "\tx = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
        "\tx = Activation('relu')(x)\n",
        "\tif DO_RATE > 0:\n",
        "\t\tx = Dropout(DO_RATE)(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\n",
        "\tx = TimeDistributed(Dense(2000))(x)\n",
        "\tx = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
        "\tx = Activation('relu')(x)\n",
        "\tif DO_RATE > 0:\n",
        "\t\tx = Dropout(DO_RATE)(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\n",
        "\tx = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\tx = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n",
        "\tprint(K.int_shape(x))\n",
        "\t\n",
        "\tif USE_VAE:\n",
        "\t\tmodel = Model(x_in, x)\n",
        "\t\tmodel.compile(optimizer=Adam(lr=LR), loss=vae_loss)\n",
        "\telse:\n",
        "\t\tmodel = Model(x_in, x)\n",
        "\t\tmodel.compile(optimizer=RMSprop(lr=LR), loss='binary_crossentropy')\n",
        "\n",
        "\tplot_model(model, to_file='/gdrive/My Drive/BeProject_v3/model.png', show_shapes=True)\n",
        "\n",
        "###################################\n",
        "#  Train\n",
        "###################################\n",
        "print(\"Compiling SubModels...\")\n",
        "func = K.function([model.get_layer('encoder').input, K.learning_phase()],\n",
        "\t\t\t\t  [model.layers[-1].output])\n",
        "enc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)\n",
        "\n",
        "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\n",
        "np.save('/gdrive/My Drive/BeProject_v3/rand.npy', rand_vecs)\n",
        "\n",
        "def make_rand_songs(write_dir, rand_vecs):\n",
        "\tfor i in range(rand_vecs.shape[0]):\n",
        "\t\tx_rand = rand_vecs[i:i+1]\n",
        "\t\ty_song = func([x_rand, 0])[0]\n",
        "\t\tsamples_to_midi(y_song[0], write_dir + 'rand' + str(i) + '.mid', 16, 0.25)\n",
        "\n",
        "def make_rand_songs_normalized(write_dir, rand_vecs):\n",
        "\tif USE_EMBEDDING:\n",
        "\t\tx_enc = np.squeeze(enc.predict(x_orig))\n",
        "\telse:\n",
        "\t\tx_enc = np.squeeze(enc.predict(y_orig))\n",
        "\t\n",
        "\tx_mean = np.mean(x_enc, axis=0)\n",
        "\tx_stds = np.std(x_enc, axis=0)\n",
        "\tx_cov = np.cov((x_enc - x_mean).T)\n",
        "\tu, s, v = np.linalg.svd(x_cov)\n",
        "\te = np.sqrt(s)\n",
        "\n",
        "\tprint(\"Means: \", x_mean[:6])\n",
        "\tprint(\"Evals: \", e[:6])\n",
        "\t\n",
        "\tnp.save(write_dir + 'means.npy', x_mean)\n",
        "\tnp.save(write_dir + 'stds.npy', x_stds)\n",
        "\tnp.save(write_dir + 'evals.npy', e)\n",
        "\tnp.save(write_dir + 'evecs.npy', v)\n",
        "\n",
        "\tx_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
        "\tmake_rand_songs(write_dir, x_vecs)\n",
        "\t\n",
        "\ttitle = ''\n",
        "\tif '/' in write_dir:\n",
        "\t\ttitle = 'Epoch: ' + write_dir.split('/')[-2][1:]\n",
        "\t\n",
        "\tplt.clf()\n",
        "\te[::-1].sort()\n",
        "\tplt.title(title)\n",
        "\tplt.bar(np.arange(e.shape[0]), e, align='center')\n",
        "\tplt.draw()\n",
        "\tplt.savefig(write_dir + 'evals.png')\n",
        "\n",
        "\tplt.clf()\n",
        "\tplt.title(title)\n",
        "\tplt.bar(np.arange(e.shape[0]), x_mean, align='center')\n",
        "\tplt.draw()\n",
        "\tplt.savefig(write_dir + 'means.png')\n",
        "\t\n",
        "\tplt.clf()\n",
        "\tplt.title(title)\n",
        "\tplt.bar(np.arange(e.shape[0]), x_stds, align='center')\n",
        "\tplt.draw()\n",
        "\tplt.savefig(write_dir + 'stds.png')\n",
        "\n",
        "if PLAY_ONLY:\n",
        "\tprint(\"Generating Songs...\")\n",
        "\tmake_rand_songs_normalized('', rand_vecs)\n",
        "\tfor i in range(20):\n",
        "\t\tx_test_song = x_train[i:i+1]\n",
        "\t\ty_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n",
        "\t\tsamples_to_midi(y_song, '/gdrive/My Drive/BeProject_v3/gt' + str(i) + '.mid', 16)\n",
        "\texit(0)\n",
        "\t\t  \n",
        "print(\"Training...\")\n",
        "save_config()\n",
        "train_loss = []\n",
        "ofs = 0\n",
        "\n",
        "for iter in range(NUM_EPOCHS):\n",
        "\tif USE_EMBEDDING:\n",
        "\t\thistory = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
        "\telse:\n",
        "\t\tcur_ix = 0\n",
        "\t\tfor i in range(num_songs):\n",
        "\t\t\tend_ix = cur_ix + y_lengths[i]\n",
        "\t\t\tfor j in range(MAX_LENGTH):\n",
        "\t\t\t\tk = (j + ofs) % (end_ix - cur_ix)\n",
        "\t\t\t\ty_train[i,j] = y_samples[cur_ix + k]\n",
        "\t\t\tcur_ix = end_ix\n",
        "\t\tassert(end_ix == num_samples)\n",
        "\t\tofs += 1\n",
        "\n",
        "\t\thistory = model.fit(y_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
        "\n",
        "\tloss = history.history[\"loss\"][-1]\n",
        "\ttrain_loss.append(loss)\n",
        "\tprint(\"Train Loss: \" + str(train_loss[-1]))\n",
        "\t\n",
        "\tif WRITE_HISTORY:\n",
        "\t\tplotScores(train_loss, '/gdrive/My Drive/BeProject_v3/History/Scores.png', True)\n",
        "\telse:\n",
        "\t\tplotScores(train_loss, '/gdrive/My Drive/BeProject_v3/Scores.png', True)\n",
        "\t\n",
        "\ti = iter + 1\n",
        "\tif i in [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450] or (i % 100 == 0):\n",
        "\t\twrite_dir = ''\n",
        "\t\tif WRITE_HISTORY:\n",
        "\t\t\t#Create folder to save models into\n",
        "\t\t\twrite_dir = '/gdrive/My Drive/BeProject_v3/History/e' + str(i)\n",
        "\t\t\tif not os.path.exists(write_dir):\n",
        "\t\t\t\tos.makedirs(write_dir)\n",
        "\t\t\twrite_dir += '/'\n",
        "\t\t\tmodel.save('/gdrive/My Drive/BeProject_v3/History/model.h5')\n",
        "\t\telse:\n",
        "\t\t\tmodel.save('/gdrive/My Drive/BeProject_v3/model.h5')\n",
        "\t\tprint(\"Saved\")\n",
        "\n",
        "\t\tif USE_EMBEDDING:\n",
        "\t\t\ty_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n",
        "\t\telse:\n",
        "\t\t\ty_song = model.predict(y_test_song, batch_size=BATCH_SIZE)[0]\n",
        "\t\t# util.samples_to_pics(write_dir + 'test', y_song)\n",
        "\t  samples_to_midi(y_song, write_dir + 'test.mid', 16)\n",
        "\n",
        "\t\tmake_rand_songs_normalized(write_dir, rand_vecs)\n",
        "\n",
        "print(\"Done\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chnht5EMdNPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bT8x-y6h-Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NjaazvMh-Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}